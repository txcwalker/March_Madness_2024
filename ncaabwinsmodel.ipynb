{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\txcwa\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#Import statements\n",
    "\n",
    "#Standard Impors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "#Model Prep\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting np random seed\n",
    "np.random.seed(42)\n",
    "#https://www.kaggle.com/competitions/march-machine-learning-mania-2024/data\n",
    "#importing data\n",
    "#Teams\n",
    "mteams = pd.read_csv(\"data/MTeams.csv\")\n",
    "wteams = pd.read_csv('data/WTeams.csv')\n",
    "\n",
    "#Renaming Team Column for both\n",
    "mteams = mteams.rename(columns = {'TeamName':'Team'})\n",
    "wteams = wteams.rename(columns = {'TeamName':'Team'})\n",
    "\n",
    "#kenpom\n",
    "kenpom_raw_df = pd.read_csv('data/kenpom_raw.csv')\n",
    "\n",
    "#Spliting Team to get tournament seed and dropping ranks for all other stats\n",
    "kenpom_df = kenpom_raw_df.drop(['Rk', 'Unnamed: 6','Unnamed: 8','Unnamed: 10','Unnamed: 12','Unnamed: 14','Unnamed: 16'\n",
    "                                ,'Unnamed: 18','Unnamed: 20'], axis = 1)\n",
    "\n",
    "kenpom_df[['Team', 'Seed']] = kenpom_df['Team'].str.extract(r'^(.*?)(\\d*)$')\n",
    "kenpom_df['Team'] = kenpom_df['Team'].str.rstrip()\n",
    "\n",
    "#The above code was used to fix some issues with the raw file and the rest was fixed in the actual excel file since it was \n",
    "#easier to do that way. Then it was loaded in the next line\n",
    "\n",
    "#Re import kenpom after fixing names\n",
    "kenpom_fin_df = pd.read_csv('data/kenpom_data.csv')\n",
    "\n",
    "# Not filled observations in Seed column are not recognized as nan so need to converted before the column can be filled and\n",
    "# finally converted to dtype int\n",
    "kenpom_fin_df['Seed'] = kenpom_fin_df['Seed'].replace('', np.nan)\n",
    "kenpom_fin_df['Seed'] = kenpom_fin_df['Seed'].fillna(99)\n",
    "kenpom_fin_df['Seed'] = kenpom_fin_df['Seed'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some of the years in the dataframe range the NIT seed is contained in the Seed column (Only for seeds 1 - 8). The\n",
    "# Function below are to work around these cases\n",
    "\n",
    "def limit_seeds(df):\n",
    "    # Sort the dataframe by Year and Seed\n",
    "    df = df.sort_values(by=['Year', 'Seed'])\n",
    "    \n",
    "    # Define the special case limits for specific seeds\n",
    "    # Play-in games can have up to 6 seeds for certain seeds (16, 10, 11, or 12) in some years\n",
    "    special_seed_limits = {\n",
    "        16: 6,  # Up to 6 teams allowed for seed 16\n",
    "        10: 6,  # Only one of 10, 11, or 12 can have 6 teams, others have 4\n",
    "        11: 6,  # We'll handle these dynamically based on data for each year\n",
    "        12: 6\n",
    "    }\n",
    "    \n",
    "    # Function to determine which of the 10, 11, 12 seeds have extra teams in a given year\n",
    "    def handle_special_cases(df, year):\n",
    "        if isinstance(year, (list, pd.Series, np.ndarray)):\n",
    "            raise ValueError(\"The 'year' parameter should be a single integer or float value.\")\n",
    "\n",
    "        # Calculate counts for seeds 10, 11, and 12\n",
    "        seed_counts = {\n",
    "            10: df[(df['Year'].between(year - 0.5, year + 0.5)) & (df['Seed'] == 10)].shape[0],\n",
    "            11: df[(df['Year'].between(year - 0.5, year + 0.5)) & (df['Seed'] == 11)].shape[0],\n",
    "            12: df[(df['Year'].between(year - 0.5, year + 0.5)) & (df['Seed'] == 12)].shape[0]\n",
    "        }\n",
    "\n",
    "        # List comprehension to include all seeds with counts > 4\n",
    "        extra_teams_seeds = [seed for seed, count in seed_counts.items() if count > 4]\n",
    "\n",
    "        # Return list of seeds with extra teams, or None if none exceed 4\n",
    "        return extra_teams_seeds if extra_teams_seeds else []\n",
    "\n",
    "    # Group by Year and Seed, then count occurrences of each seed\n",
    "    df['Seed_Count'] = df.groupby(['Year', 'Seed']).cumcount() + 1\n",
    "    \n",
    "    # Iterate through each year to apply limits\n",
    "    for year in df['Year'].unique():\n",
    "        \n",
    "        # Handle seed 16 separately (always 6 teams in play-in cases)\n",
    "        mask_16 = (df['Year'].between(year - 0.5, year + 0.5)) & (df['Seed'] == 16)\n",
    "        df.loc[mask_16 & (df['Seed_Count'] > special_seed_limits[16]), 'Seed'] = 99\n",
    "        \n",
    "        # Determine which seed (10, 11, or 12) has the extra teams\n",
    "        extra_seeds = handle_special_cases(df, year)\n",
    "        \n",
    "        # Apply the special limit for seeds with extra teams\n",
    "        if extra_seeds is not None:\n",
    "            for seed in extra_seeds:\n",
    "                mask_extra = (df['Year'] == year) & (df['Seed'] == seed)\n",
    "                df.loc[mask_extra & (df['Seed_Count'] > special_seed_limits[seed]), 'Seed'] = 99\n",
    "        # Apply the default limit of 4 for other seeds\n",
    "        for seed in range(1,16):\n",
    "            if seed not in extra_seeds:\n",
    "\n",
    "                mask_other = (df['Year'] == year) & (df['Seed'] == seed)\n",
    "                df.loc[mask_other & (df['Seed_Count'] > 4), 'Seed'] = 99\n",
    "    \n",
    "    # Drop the helper Seed_Count column\n",
    "    df.drop('Seed_Count', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fuunction and sanity check\n",
    "kenpom_fin_df = limit_seeds(kenpom_fin_df)\n",
    "seed_check = kenpom_fin_df.value_counts('Seed')\n",
    "# seed_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with MTeams to add Team ID to kenpom\n",
    "kenpom_fin_df = kenpom_fin_df.merge(mteams, how = 'inner', on = 'Team')\n",
    "kenpom_fin_df = kenpom_fin_df.rename(columns = {'AdjEM.1':'AdjEM_SOS','AdjEM.2':'AdjEM_NCSOS', 'Year':'Season'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Seasons, Tournament seeds and results\n",
    "# Not all data was used, further models could use more data or already used data different, this comment is being made once \n",
    "# the code as a whole was completed, at the start everything that seemed halfway useable was loaded\n",
    "\n",
    "# Seasons\n",
    "mseasons_df = pd.read_csv('data/MSeasons.csv')\n",
    "wseasons_df = pd.read_csv('data/WSeasons.csv')\n",
    "\n",
    "# Seeds\n",
    "mseeds_df = pd.read_csv('data/MNCAATourneySeeds.csv')\n",
    "wseeds_df = pd.read_csv('data/WNCAATourneySeeds.csv')\n",
    "\n",
    "# Regular season results - compact\n",
    "mregresultscomp_df = pd.read_csv('data/MRegularSeasonCompactResults.csv')\n",
    "wregresultscomp_df = pd.read_csv('data/WRegularSeasonCompactResults.csv')\n",
    "\n",
    "# Tournament Results - compact\n",
    "mmadresultscomp_df = pd.read_csv('data/MNCAATourneyCompactResults.csv')\n",
    "wmadresultscomp_df = pd.read_csv('data/WNCAATourneyCompactResults.csv')\n",
    "\n",
    "# Regular season results - detailed\n",
    "mregresultsdet_df = pd.read_csv('data/MRegularSeasonDetailedResults.csv')\n",
    "wregresultsdet_df = pd.read_csv('data/WRegularSeasonDetailedResults.csv')\n",
    "\n",
    "# Tournament Results - detailed\n",
    "mmadresultsdet_df = pd.read_csv('data/MNCAATourneyDetailedResults.csv')\n",
    "wmadresultsdet_df = pd.read_csv('data/WNCAATourneyDetailedResults.csv')\n",
    "\n",
    "# Coaches\n",
    "mcoaches_df = pd.read_csv('data/MTeamCoaches.csv')\n",
    "\n",
    "# Conferences\n",
    "conf_df = pd.read_csv('data/Conferences.csv')\n",
    "mconf_df = pd.read_csv('data/MTeamConferences.csv')\n",
    "wconf_df = pd.read_csv('data/WTeamConferences.csv')\n",
    "\n",
    "# Conference Tournament Results and Non March Madness tournament teams + results\n",
    "mconftourn_df = pd.read_csv('data/MConferenceTourneyGames.csv')\n",
    "msectournteams_df = pd.read_csv('data/MSecondaryTourneyTeams.csv')\n",
    "msectournres_df = pd.read_csv('data/MSecondaryTourneyCompactResults.csv')\n",
    "\n",
    "# Tournament Slots\n",
    "mtournslot_df = pd.read_csv('data/MNCAATourneySlots.csv')\n",
    "wtournslot_df = pd.read_csv('data/WNCAATourneySlots.csv')\n",
    "mseedslot_df = pd.read_csv('data/MNCAATourneySeedRoundSlots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kenpom data only goes to 2003 so we are droping anything before\n",
    "\n",
    "# List of all DataFrames for below for loop\n",
    "dataframes = [mseasons_df, wseasons_df, mseeds_df, wseeds_df,\n",
    "              mregresultscomp_df, wregresultscomp_df, mmadresultscomp_df,\n",
    "              wmadresultscomp_df, mregresultsdet_df, wregresultsdet_df,\n",
    "              mmadresultsdet_df, wmadresultsdet_df, mcoaches_df, conf_df,\n",
    "              mconf_df, wconf_df, mconftourn_df, msectournteams_df,\n",
    "              msectournres_df, mtournslot_df, mseedslot_df]\n",
    "\n",
    "# Removing years not in kenpom data\n",
    "for df in dataframes:\n",
    "    # Check if 'Year' or 'Season' column exists\n",
    "    if 'Year' in df.columns:\n",
    "        # Drop rows where 'Year' is before 2003\n",
    "        df.drop(df[(df['Year'] < 2003)].index, inplace=True)\n",
    "    elif 'Season' in df.columns:\n",
    "        # Drop rows where 'Season' is before 2003\n",
    "        df.drop(df[(df['Season'] < 2003)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying winning Team to new column\n",
    "mregresultscomp_df.reset_index(inplace=True)\n",
    "mregresultscomp_df['Winner'] = mregresultscomp_df['WTeamID']\n",
    "\n",
    "# Seperating the TeamIDs for Merge\n",
    "# Need to merge kenpom data for each team. In order to accomplish the oringal df is being split on TeamID, merged by team\n",
    "# with kenpom so that each on row will be a game with each team and their respective kenpom stats\n",
    "wgames_df = mregresultscomp_df[['index','Season','DayNum', 'WTeamID','WScore','WLoc', 'NumOT','Winner']]\n",
    "lgames_df = mregresultscomp_df[['index','Season','DayNum', 'LTeamID','LScore','WLoc', 'NumOT']]\n",
    "\n",
    "# Renaming TeamID Columns to Team ID, will be renamed to TeamID_A and TeamID_B on final merge\n",
    "wgames_df = wgames_df.rename(columns = {'WTeamID':'TeamID'})\n",
    "lgames_df = lgames_df.rename(columns = {'LTeamID':'TeamID'})\n",
    "\n",
    "# Merging with kenpom\n",
    "wgames_df = wgames_df.merge(kenpom_fin_df, on =['TeamID','Season'])\n",
    "lgames_df = lgames_df.merge(kenpom_fin_df, on =['TeamID','Season'])\n",
    "\n",
    "# Recreating for Tournament games\n",
    "# Copying winning Team to new column and switching everything to\n",
    "mmadresultsdet_df['Winner'] = mmadresultsdet_df['WTeamID']\n",
    "\n",
    "# Seperating the TeamIDs for Merge\n",
    "wgamestourn_df = mmadresultsdet_df[['Season','DayNum', 'WTeamID','WScore','WLoc', 'NumOT','Winner']]\n",
    "lgamestourn_df = mmadresultsdet_df[['Season','DayNum', 'LTeamID','LScore','WLoc', 'NumOT']]\n",
    "\n",
    "# Renaming TeamID Columns to Team ID, will be renamed to TeamID_A and TeamID_B on final merge\n",
    "wgamestourn_df = wgamestourn_df.rename(columns = {'WTeamID':'TeamID'})\n",
    "lgamestourn_df = lgamestourn_df.rename(columns = {'LTeamID':'TeamID'})\n",
    "\n",
    "# Merging with kenpom\n",
    "wgamestourn_df = wgamestourn_df.merge(kenpom_fin_df, on =['TeamID','Season'])\n",
    "lgamestourn_df = lgamestourn_df.merge(kenpom_fin_df, on =['TeamID','Season'])\n",
    "\n",
    "\n",
    "# Merging everthing together\n",
    "games_df = wgames_df.merge(lgames_df, on = 'index' ,suffixes = ('_A', '_B'))\n",
    "gamestourn_df = wgamestourn_df.merge(lgamestourn_df, left_index = True, right_index = True ,suffixes = ('_A', '_B'))\n",
    "\n",
    "# Final df form for analysis\n",
    "allgames_df = pd.concat([games_df, gamestourn_df], axis = 0)\n",
    "\n",
    "# Prepping Everything for analysis\n",
    "allgames_df = allgames_df.drop(columns = ['index','Season_B', 'DayNum_B','WLoc_B','NumOT_B'])#'W-L_A','W-L_B',\n",
    "allgames_df = allgames_df.rename(columns = {'Season_A':'Season', 'DayNum_A':'DayNum','WLoc_A':'WLoc','NumOT_A':'NumOT'})\n",
    "\n",
    "# Split the W-L column into two columns: W and L\n",
    "allgames_df[['W_A', 'L_A']] = allgames_df['W-L_A'].str.split('-', expand=True)\n",
    "allgames_df[['W_B', 'L_B']] = allgames_df['W-L_B'].str.split('-', expand=True)\n",
    "\n",
    "# Convert both columns to numeric\n",
    "allgames_df['W_A'] = pd.to_numeric(allgames_df['W_A'])\n",
    "allgames_df['L_A'] = pd.to_numeric(allgames_df['L_A'])\n",
    "\n",
    "# Convert both columns to numeric\n",
    "allgames_df['W_B'] = pd.to_numeric(allgames_df['W_B'])\n",
    "allgames_df['L_B'] = pd.to_numeric(allgames_df['L_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping more columns\n",
    "allgames_df = allgames_df.drop(columns=['Team_A', 'Team_B', 'WLoc', 'WScore', 'LScore', 'NumOT', 'DayNum', 'Winner'])\n",
    "\n",
    "# Conference dictionary mapping for abbreviation\n",
    "conf_mapping = {\n",
    "    'SEC': 'sec',\n",
    "    'CUSA': 'cusa',\n",
    "    'MAC': 'mac',\n",
    "    'B12': 'big_twelve',\n",
    "    'B10': 'big_ten',\n",
    "    'MWC': 'mwc',\n",
    "    'BSky': 'big_sky',\n",
    "    'ASun': 'a_sun',\n",
    "    'MVC': 'mvc',\n",
    "    'BE': 'big_east',\n",
    "    'Horz': 'horizon',\n",
    "    'OVC': 'ovc',\n",
    "    'ACC': 'acc',\n",
    "    'P10': 'pac_ten',\n",
    "    'Slnd': 'southland',\n",
    "    'A10': 'aac',\n",
    "    'SB': 'sun_belt',\n",
    "    'Ivy': 'ivy',\n",
    "    'WCC': 'wcc',\n",
    "    'WAC': 'wac',\n",
    "    'CAA': 'caa',\n",
    "    'Pat': 'patriot',\n",
    "    'MAAC': 'maac',\n",
    "    'NEC': 'nec',\n",
    "    'AE': 'aec',\n",
    "    'SWAC': 'swac',\n",
    "    'MEAC': 'meac',\n",
    "    'Sum': 'summit',\n",
    "    'P12': 'pac_twelve',\n",
    "    'Amer': 'americ_east'\n",
    "}\n",
    "\n",
    "# Apply conference mapping to Conf_A and Conf_B columns\n",
    "allgames_df['Conf_A'] = allgames_df['Conf_A'].map(conf_mapping)\n",
    "allgames_df['Conf_B'] = allgames_df['Conf_B'].map(conf_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conference tiers definition based on 2024 seeding results\n",
    "conference_tiers = {\n",
    "    'sec': 1, 'big_twelve': 1, 'big_ten': 1, 'acc': 1, 'big_east': 1, 'pac_twelve': 1, 'mwc': 1,\n",
    "    'aac': 2, 'americ_east': 2, 'mvc': 2, 'wcc': 2\n",
    "}\n",
    "\n",
    "# Assign Tier 3 to the rest of the conferences\n",
    "all_conferences = set(conf_mapping.values())\n",
    "tier_three_conferences = all_conferences - set(conference_tiers.keys())\n",
    "conference_tiers.update({conf: 3 for conf in tier_three_conferences})\n",
    "\n",
    "# Create a function to map conferences to tiers\n",
    "def map_tier(conf):\n",
    "    return conference_tiers.get(conf, 3)  # Default to tier 3 if not found\n",
    "\n",
    "# Apply conference tier mapping to Conf_A and Conf_B columns\n",
    "allgames_df['Conf_Tier_A'] = allgames_df['Conf_A'].apply(map_tier)\n",
    "allgames_df['Conf_Tier_B'] = allgames_df['Conf_B'].apply(map_tier)\n",
    "\n",
    "# Create LabelEncoder object (for conferences)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform Conf_A and Conf_B columns to integers\n",
    "allgames_df['Conf_A'] = label_encoder.fit_transform(allgames_df['Conf_A'])\n",
    "allgames_df['Conf_B'] = label_encoder.fit_transform(allgames_df['Conf_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine random team ID\n",
    "def random_id(row):\n",
    "    return np.random.choice([row['TeamID_A'], row['TeamID_B']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the new column 'RandID' by applying random_id function\n",
    "allgames_df['RandID'] = allgames_df.apply(random_id, axis=1)\n",
    "\n",
    "#Creating variable to be dependent variable in model\n",
    "allgames_df['WinnerID'] = allgames_df['TeamID_A']\n",
    "\n",
    "#Saving final df so it can be visualized easier in case of debugging\n",
    "allgames_df.to_csv('data/_allgamescheck.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make sure that the winning team is not always listed first in the dataframe \n",
    "def stat_swap(df):\n",
    "    # Empty list to store the result rows\n",
    "    selected_rows = []\n",
    "\n",
    "    # Static columns that should always be present\n",
    "    static_columns = ['Season', 'RandID', 'WinnerID']\n",
    "\n",
    "    # Get the columns ending in _A and _B\n",
    "    columns_A = [col for col in df.columns if col.endswith('_A')]\n",
    "    columns_B = [col for col in df.columns if col.endswith('_B')]\n",
    "\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # If RandID == TeamID_A, we keep the values as is\n",
    "        if row['RandID'] == row['TeamID_A']:\n",
    "            selected_data = row.to_dict()\n",
    "        \n",
    "        # If RandID == TeamID_B, we swap values between _A and _B columns\n",
    "        else:\n",
    "            selected_data = row.to_dict()  # Start by copying the row data\n",
    "            \n",
    "            # Swap the values of _A and _B columns\n",
    "            for col_A, col_B in zip(columns_A, columns_B):\n",
    "                selected_data[col_A], selected_data[col_B] = selected_data[col_B], selected_data[col_A]\n",
    "\n",
    "        # Add static columns to the result\n",
    "        result_row = {col: selected_data[col] for col in static_columns + columns_A + columns_B}\n",
    "        selected_rows.append(result_row)\n",
    "\n",
    "    # Convert the result list into a DataFrame\n",
    "    selected_df = pd.DataFrame(selected_rows)\n",
    "    \n",
    "    return selected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying stat swap\n",
    "allgames_df2 = stat_swap(allgames_df)\n",
    "\n",
    "# Creating variable to be dependent variable in model\n",
    "allgames_df2['Winner'] = (allgames_df2['WinnerID'] == allgames_df2['RandID']).astype(int)\n",
    "\n",
    "# Sanity check to make sure winner is being correctly randomally assigned.\n",
    "# Current process is to randomly chose a TeamID in the matchup data and compare it to the WinnerID if the\n",
    "# two are the same Winner == 1 else Winner == 0\n",
    "# sum(allgames_df2['Winner'])/len(allgames_df2)\n",
    "\n",
    "# Dropping both TeamIDs so that model does not see that TeamID_A is always the winner\n",
    "allgames_df2 = allgames_df2.drop(columns = (['W-L_A','W-L_B','RandID','WinnerID','W_A','L_A','W_B','L_B']))#['TeamID_A', 'TeamID_B',]\n",
    "\n",
    "# Filling Seed variable for teams that did not make the the tournament, might need to add logic for NIT\n",
    "allgames_df2['Seed_A'] = allgames_df2['Seed_A'].fillna(99)\n",
    "allgames_df2['Seed_B'] = allgames_df2['Seed_B'].fillna(99)\n",
    "\n",
    "# Saving final df so it can be visualized easier in case of debugging\n",
    "allgames_df2.to_csv('data/_allgames2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns which proved to be extraneous in the model to get a more streamlined, less complex outcome\n",
    "allgames_df2 = allgames_df2.drop(columns = (['Luck_A','Luck_B','AdjEM_A','AdjEM_B','FirstD1Season_B', 'LastD1Season_B','FirstD1Season_A', 'LastD1Season_A']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model:\n",
    "Mean cross-validation accuracy: 0.7152072280919193\n",
    "Log Loss: 0.5811\n",
    "Accuracy: 0.7163\n",
    "Precision: 0.7145\n",
    "Recall: 0.7177\n",
    "F1 Score: 0.7161\n",
    "Expected Calibration Error (ECE): 0.0623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without luck\n",
    "Mean cross-validation accuracy:  0.7108149633506813\n",
    "Log Loss: 0.5956\n",
    "Accuracy: 0.7147\n",
    "Precision: 0.7133\n",
    "Recall: 0.7152\n",
    "F1 Score: 0.7143\n",
    "Expected Calibration Error (ECE): 0.0678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Luck and Overall Kenpom Ranking Value (AdjEM)\n",
    "Mean cross-validation accuracy: 0.7095944031306631\n",
    "Log Loss: 0.5862\n",
    "Accuracy: 0.7121\n",
    "Precision: 0.7113\n",
    "Recall: 0.7113\n",
    "F1 Score: 0.7113\n",
    "Expected Calibration Error (ECE): 0.0558"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Luck, AdjEM, First and Last D1 Season\n",
    "Mean cross-validation accuracy:  0.7094607593478615\n",
    "Log Loss: 0.5820\n",
    "Accuracy: 0.7118\n",
    "Precision: 0.7097\n",
    "Recall: 0.7139\n",
    "F1 Score: 0.7118\n",
    "ROC-AUC Score: 0.7786\n",
    "Best Threshold by Youdenâ€™s J statistic: 0.4867\n",
    "Expected Calibration Error (ECE): 0.0556"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
